
### Projection Transform

**Kamerakoordinaten ü°™ Clip-Koordinaten**

Mit diesem Transformationsschritt wollen wir Perspektivische Projektion unter Beachtung von Blickwinkeln sowie near und far clipping plane realisieren.
Daf√ºr m√ºssen wir uns zun√§chst √ºberlegen, wie sich perspektivische Verzerrung auf das Bild auswirkt und wie wir den Effekt mathematisch beschreiben k√∂nnen. Unsere Intuition sagt uns bereits, dass n√§here Objekte gr√∂√üer erscheinen als weit entfernte Objekte.

Mit dem Strahlensatz k√∂nnen wir beschreiben, wie gro√ü genau ein Objekt auf einer Projektionsebene erscheint.

**EINSCHUB PROJEKTIONSEBENE**

Wir betrachten zun√§chst nur die obere H√§lfte des Sichtvolumens, das wird uns sp√§ter Rechnungen vereinfachen.

Angenommen, wir kennen also den Abstand der Projektionsebene von der Kamera. Wie ermitteln wir, wie gro√ü ein Objekt mit Abstand $z_o$ auf der Projektionsebene erscheint? Gegeben sind dabei die Objektgr√∂√üe o, der Abstand des Objekts $z$ und der Abstand der Projektionsebene $z_p$.

| ![camera-model](./strahlensatz1.jpg?as=webp) |
| :--------------: |
| :jigsaw: Illustration Strahlensatz |


<textarea class = 'notes' rows = '8' placeholder = 'Mach Dir ein paar Notizen wenn du magst.'></textarea> 

Wir wissen, dass die Objektgr√∂√üe $o$ im Verh√§ltnis zu $h_o$ genauso gro√ü ist wie die projizierte Gr√∂√üe $proj$ im Verh√§ltnis zu $d$.

Demnach gilt $$
proj=\frac{o\cdot z_p}{z_o}.$$

Relevant f√ºr uns ist nun aber weniger die absolute Gr√∂√üe der Projektion als die Gr√∂√üe der Projektion in Relation zur Projektionsfl√§che, deren Gr√∂√üe wir mit $d$ bezeichnet haben.
Wie zuvor schon festgestellt, ist das Verh√§ltnis von $o$ zu $b$ genauso wie das Verh√§ltnis von $proj$ zu $d$ und genau das Verh√§ltnis, das wir suchen.
$$
\frac{o}{h_o}=\frac{proj}{h_p}
$$

| ![camera-model](./strahlensatz2.jpg?as=webp) |
| :--------------: |
| :jigsaw: Illustration Strahlensatz |

K√∂nnten wir also $h_o$ mit bekannten Gr√∂√üen beschreiben, h√§tten wir das gesuchte Verh√§ltnis gefunden. Dabei k√∂nnen wir uns zunutze machen, dass √ºber die Kameraparameter der Winkel $\alpha$ ebenfalls bekannt ist. Dieser entspricht der H√§lfte des Sichtwinkels $\theta_y$ in y-Richtung. Damit k√∂nnen wir Beziehungen am rechtwinkligen Dreieck nutzen und erhalten$$
\tan{\alpha}=\tan{(\theta_y}/2)=\frac{h_o}{z_p}
$$ und damit $$
\frac{o}{h_o}=\frac{o}{\tan{(\theta_y}/2)\cdot a}.
$$

Wir haben damit also eine Formel, um die Gr√∂√üe eines Objektes in Relation zum Gesamtbild zu beschreiben. Die Skalierung ist dabei abh√§ngig von dem Winkel der beiden Strahlen und von der Entfernung des Objektes. In x-Richtung, also f√ºr ein von oben betrachtetes Frustum, funktioniert die Herleitung analog mit $\theta_x$ statt $\theta_y$.

Wie k√∂nnen wir daraus nun eine geometrische Transformation ableiten?
Da wir die Objektgr√∂√üe, die ja durch x- und y-Koordinate bestimmt ist, durch einen Wert teilen, liegt es nahe, eine Skalierung in x- und y-Richtung durchzuf√ºhren. Mit $\tan{(\theta_x}/2)$ bzw. $\tan{(\theta_y}/2)$ ist das ohne weiteres m√∂glich, da diese Terme nicht von den skalierten Koordinaten abh√§ngen. Ein erster Schritt unserer Transformation ist also die

**I Winkel√§nderung des Sichtvolumens (xy-Skalierung)**

Daf√ºr m√ºssen wir lediglich die eben berechneten Terme in die Transformationsmatrix eintragen und erhalten $$
                    P_I =
                    \begin{pmatrix}
                        \frac{1}{\tan(\theta_x/2)} & 0 & 0 & 0 \\
                        0 & \frac{1}{\tan(\theta_y/2)} & 0 & 0 \\
                        0 & 0 & 1 & 0 \\
                        0 & 0 & 0 & 1 \\
                    \end{pmatrix}=
                    \begin{pmatrix}
                        \cot(\theta_x/2) & 0 & 0 & 0 \\
                        0 & \cot(\theta_y/2) & 0 & 0 \\
                        0 & 0 & 1 & 0 \\
                        0 & 0 & 0 & 1 \\
                    \end{pmatrix}.
$$
Diese Transformation bewirkt, dass der Sichtwinkel auf 90¬∞ transformiert wird. Die Tiefe wird dabei nicht ver√§ndert.

| ![camera-model](./fov_scaling.png?as=webp) |
| :--------------: |
| :jigsaw: Visualisierung der Skalierung des Sichtvolumens |

**II Skalierung des Sichtvolumens**

Bevor wir uns mit der Umsetzung der tats√§chlichen perspektivischen Verzerrung besch√§ftigen, m√ºssen wir noch einen weiteren Aspekt ber√ºcksichtigen. Denn wie bereits zuvor erw√§hnt, sollen die Objekte der Szene nicht nur relativ zueinander korrekt skaliert sein, nach der Transformation sollen auch alle Koordinaten im Bereich [-1, 1] liegen. Wir wollen also die gesamte Szene so skalieren, dass die far plane bei 1 liegt.

Die Proportionen sollen dabei erhalten bleiben. Das realisieren wir durch folgende Matrix:$$
                    P_{II}=\begin{pmatrix}
                        \frac{1}{far} & 0 & 0 & 0 \\
                        0 & \frac{1}{far} & 0 & 0 \\
                        0 & 0 & \frac{1}{far} & 0 \\
                        0 & 0 & 0 & 1 \\
                    \end{pmatrix}
$$

**III Perspektivische Transformation**

Mit dieser Vorbereitung k√∂nnen wir endlich die tats√§chliche perspektivische Verzerrung umsetzen.
Daf√ºr m√ºssen wir ‚Äì wenn wir eine Transformationsmatrix verwenden wollen ‚Äì homogene Koordinaten verwenden.

Wenn du dich sicher mit der Mathematik f√ºhlst, kannst du versuchen, selbst herzuleiten, warum wir perspektivische Verzerrung nicht ohne homogene Koordinaten realisieren k√∂nnen. Ansonsten scrolle einfach weiter.
<textarea class = 'notes' rows = '8' placeholder = 'Mach Dir ein paar Notizen wenn du magst.'></textarea>

Die Begr√ºndung, warum wir homogene Koordinaten ben√∂tigen, l√§sst sich gut anschaulich darstellen. Ohne homogene Koordinaten k√∂nnen wir nur lineare Abbildungen vom $\mathbb{R}^3$ zum $\mathbb{R}^3$-Raum realisieren.

Diese m√ºssen f√ºr alle $\lambda\in \mathbb{R},a\in \mathbb{R}^3$ die Eigenschaft $f\left(\lambda a\right)=\lambda f\left(a\right)$ erf√ºllen. Sehen wir uns den folgenden Vektor an, der zu einer Kante des Frustums verl√§uft.

| ![camera-model](./homogenous1.jpg?as=webp) |
| :--------------: |

Durch die Anwendung der perspektivischen Projektion wird das pyramidenf√∂rmige Frustum zu einem Quader verzerrt. Das Ergebnis sieht folgenderma√üen aus:

| ![camera-model](./homogenous2.jpg?as=webp) |
| :--------------: |

Offensichtlich gilt dabei $f\left(2a\right)\neq2f\left(a\right)$, damit ist die perspektivische Verzerrung keine lineare Abbildung f√ºr den $\mathbb{R}^3$.

Doch im Gegensatz zur Translation wird die perspektivische Verzerrung nicht auf einmal linear, wenn wir sie mit den homogenen Koordinaten in den $\mathbb{R}^4$ erweitern. Das l√§sst sich am besten damit anschaulich erkl√§ren, dass mit Matrixmultiplikation nur Multiplikation mit den Koordinaten und Addition der Ergebnisse erlaubt, Dividieren durch eine Koordinate ist also nicht m√∂glich. Wie k√∂nnen wir diese Transformation dann mittels homogener Koordinaten umsetzen?
